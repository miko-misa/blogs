# 非階層的クラスタリング
## クラスタ分析
**クラスタ分析**（clustering analysis; クラスタリング）とは、データをいくつかのグループ（**クラスタ**）に分ける手法の総称である。クラスタ分析は教師なし学習の一種であり、データにラベルが付与されていない場合でもデータを分類できる。つまり、分類問題とは違い、あらかじめデータがどのグループに属するかが分かっていなくても、データをグループに分けることができる。

各事例を$RR^d$のベクトルとしたデータセット$cal(D) = {bold(x)_1, bold(x)_2, ..., bold(x)_n}$を考えられる。このデータセットをクラス$C_1, C_2, ..., C_k$に分割することを考える。ここで、$K$はクラス数で各$C_i$は事例の添え字（インデックス）の集合であり以下の条件を満たす。

- $union.big_(i=1)^K C_i = {1, 2, ..., n}$ （すべての事例がいずれかのクラスに属する）
- $i eq.not j => C_i union C_j = emptyset$ （異なるクラスは共通の事例を持たない）

## k-means法
クラスタリングの基本的な考え方は、「似たベクトルは同じクラスに、異なるクラスに属するベクトルは遠くに」である。k-means法では各クラス$C_i$の**重心/中心ベクトル**（centroid）$bold(mu)_i$をもってそのクラス$C_i$を代表させる。
$$
bold(mu)_i = 1/(|C_i|) sum_(j in C_i) bold(x)_j
$$
そして、そのクラスに属しているベクトルと$bold(mu)_i$との距離の二乗和を考えると
$$
sum_(j in C_i) ||bold(x)_j - bold(mu)_i||_2^2
$$
これは事例の偏差平方和に相当する。したがって、全クラスにわたるこの値の総和$cal(J)$を考える。
$$
cal(J) = sum_(i=1)^K sum_(j in C_i) ||bold(x)_j - bold(mu)_i||_2^2
$$
この$cal(J)$を**歪み尺度**（distortion measure）や**クラスタ内平方和**（within-cluster sum of squares; WCSS）と呼ぶ。k-means法では、この$cal(J)$を最小化するようにクラス$C_1, C_2, ..., C_K$を決定する。

## Lloydのアルゴリズム
k-means法で$cal(J)$を最小化するクラス分けを見つけるために、**Lloydのアルゴリズム**（Lloyd's algorithm）がよく用いられる。このアルゴリズムは以下の手順で行われる。

::: box Lloydのアルゴリズム
1. 全てのクラスの中心ベクトル$bold(mu)_1, bold(mu)_2, ..., bold(mu)_K$をランダムに初期化する。
2. 各事例$bold(x)_j$について、最も近い中心ベクトル$bold(mu)_(hat(k)(j))$を見つけ、その事例をクラス$C_(hat(k)(j))$に割り当てる。
    $$
    hat(k) (j) &:= op("argmin", limits: #true)_(k in {1, 2, dots, K}) ||bold(x)_j - bold(mu)_k||_2
    $$
3. 各クラス$C_i$の中心ベクトル$bold(mu)_i$を再計算する。
4. $cal(J)$の変化が十分小さくなるまで、2に戻る。
:::

Lloydのアルゴリズムは局所最適解に収束するが、必ずしも大域最適解に収束するとは限らない。そのため、異なる初期化を用いて複数回実行し、最も良い結果を採用することが一般的である。

また$K$の値は事前に決定する必要があるが、適切な$K$の選択は難しい問題である。基本的に$K$を大きくすると$cal(J)$は小さくなるが、過学習のリスクも高まる。

## ボロノイ図
Lloydのアルゴリズムにおける各事例のクラス割り当ては、各中心ベクトルに基づいて**ボロノイ図**（Voronoi diagram）を形成する。ボロノイ図は、$RR^d$空間において、ある点が最も近い中心ベクトルに属するような領域を示す図である。各中心ベクトル$bold(mu)_i$に対して、その点から最も近い点の集合は以下のように定義される。
$$
V_i = { bold(x) in RR^d | forall j eq.not i, ||bold(x) - bold(mu)_i||_2 <= ||bold(x) - bold(mu)_j||_2 }
$$
この$V_i$を**ボロノイ領域**（Voronoi region）と呼ぶ。Lloydのアルゴリズムにおいて、各事例$bold(x)_j$は、その点が属するボロノイ領域に対応するクラスに割り当てられる。

## k-means法の性質
k-means法はシンプルで計算効率が高いため、広く利用されている。しかし、いくつかの制約や欠点も存在する。例えば、k-means法は各クラスが球状で同じ大きさを持つことを前提としているため、非球状や異なる大きさのクラスタには適していない。また、外れ値に敏感であり、外れ値がクラスタの中心に大きな影響を与える可能性がある。さらに、k-means法は初期化に依存するため、異なる初期化により異なる結果、つまり、$cal(J)$の最小化が異なる**特殊解**に収束する可能性がある。
